{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'AsyncOpenAI' from 'openai' (/home/kiwitech/Erloom-AI/lib/python3.10/site-packages/openai/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnode_parser\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SemanticSplitterNodeParser\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgemini\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GeminiEmbedding\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgroq\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Groq\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpostprocessor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcohere_rerank\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CohereRerank\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n",
      "File \u001b[0;32m~/Erloom-AI/lib/python3.10/site-packages/llama_index/llms/groq/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgroq\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Groq\n\u001b[1;32m      3\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGroq\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Erloom-AI/lib/python3.10/site-packages/llama_index/llms/groq/base.py:4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Any, Optional\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mopenai_like\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAILike\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mGroq\u001b[39;00m(OpenAILike):\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m      9\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     10\u001b[0m         model: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m     15\u001b[0m     ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Erloom-AI/lib/python3.10/site-packages/llama_index/llms/openai_like/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mopenai_like\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAILike\n\u001b[1;32m      3\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOpenAILike\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Erloom-AI/lib/python3.10/site-packages/llama_index/llms/openai_like/base.py:20\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstants\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DEFAULT_CONTEXT_WINDOW\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeneric_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     16\u001b[0m     async_stream_completion_response_to_chat_response,\n\u001b[1;32m     17\u001b[0m     completion_response_to_chat_response,\n\u001b[1;32m     18\u001b[0m     stream_completion_response_to_chat_response,\n\u001b[1;32m     19\u001b[0m )\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mopenai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAI, Tokenizer\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mOpenAILike\u001b[39;00m(OpenAI):\n",
      "File \u001b[0;32m~/Erloom-AI/lib/python3.10/site-packages/llama_index/llms/openai/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mopenai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AsyncOpenAI, OpenAI, SyncOpenAI, Tokenizer\n\u001b[1;32m      3\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOpenAI\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSyncOpenAI\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAsyncOpenAI\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Erloom-AI/lib/python3.10/site-packages/llama_index/llms/openai/base.py:60\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseOutputParser, PydanticProgramMode\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mopenai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     49\u001b[0m     create_retry_decorator,\n\u001b[1;32m     50\u001b[0m     from_openai_message,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     57\u001b[0m     to_openai_message_dicts,\n\u001b[1;32m     58\u001b[0m )\n\u001b[0;32m---> 60\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mopenai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AsyncOpenAI, AzureOpenAI\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mopenai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAI \u001b[38;5;28;01mas\u001b[39;00m SyncOpenAI\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mopenai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat_completion_chunk\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     63\u001b[0m     ChatCompletionChunk,\n\u001b[1;32m     64\u001b[0m     ChoiceDelta,\n\u001b[1;32m     65\u001b[0m     ChoiceDeltaToolCall,\n\u001b[1;32m     66\u001b[0m )\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'AsyncOpenAI' from 'openai' (/home/kiwitech/Erloom-AI/lib/python3.10/site-packages/openai/__init__.py)"
     ]
    }
   ],
   "source": [
    "from llama_index.core import (\n",
    "    VectorStoreIndex, \n",
    "    SimpleDirectoryReader, \n",
    "    StorageContext, \n",
    "    ServiceContext, \n",
    "    load_index_from_storage\n",
    ")\n",
    "from llama_index.core.node_parser import SemanticSplitterNodeParser\n",
    "from llama_index.embeddings.gemini import GeminiEmbedding\n",
    "from llama_index.llms.groq import Groq\n",
    "from llama_index.postprocessor.cohere_rerank import CohereRerank\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting docx2txt\n",
      "  Using cached docx2txt-0.8-py3-none-any.whl\n",
      "Installing collected packages: docx2txt\n",
      "Successfully installed docx2txt-0.8\n"
     ]
    }
   ],
   "source": [
    "!pip install docx2txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "GOOGLE_API_KEY =\"AIzaSyB1SoF4qBbyJbGLY5lcdyevX9JQ97NJe7Y\"\n",
    "GROQ_API_KEY=\"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\"\n",
    "COHERE_API_KEY=\"uSmH32NPyGFVENXCzxgw4BxfL6SAl9rbEQXVdocP\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = SimpleDirectoryReader(input_dir=\"/home/kiwitech/adnan_zafar/extractions/main_code/data_final\")\n",
    "documents = reader.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing nodes:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings: 100%|██████████| 10/10 [00:09<00:00,  1.04it/s]\n",
      "Generating embeddings: 100%|██████████| 8/8 [00:06<00:00,  1.19it/s]\n",
      "Generating embeddings: 100%|██████████| 6/6 [00:04<00:00,  1.23it/s]\n",
      "Generating embeddings: 100%|██████████| 8/8 [00:06<00:00,  1.20it/s]\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:01<00:00,  1.15it/s]\n",
      "Generating embeddings: 100%|██████████| 37/37 [00:22<00:00,  1.64it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.74it/s]\n",
      "Generating embeddings: 100%|██████████| 19/19 [00:10<00:00,  1.82it/s]\n",
      "Generating embeddings: 100%|██████████| 6/6 [00:03<00:00,  1.68it/s]\n",
      "Generating embeddings: 100%|██████████| 31/31 [00:17<00:00,  1.79it/s]\n",
      "Generating embeddings: 100%|██████████| 30/30 [00:15<00:00,  1.91it/s]\n",
      "Generating embeddings: 100%|██████████| 41/41 [00:22<00:00,  1.83it/s]\n",
      "Generating embeddings: 100%|██████████| 3/3 [00:01<00:00,  1.58it/s]\n",
      "Generating embeddings: 100%|██████████| 26/26 [00:13<00:00,  1.88it/s]\n",
      "Generating embeddings: 100%|██████████| 16/16 [00:08<00:00,  1.81it/s]\n",
      "Generating embeddings: 100%|██████████| 4/4 [00:01<00:00,  2.13it/s]\n",
      "Generating embeddings: 100%|██████████| 22/22 [00:11<00:00,  1.97it/s]\n",
      "Generating embeddings: 100%|██████████| 43/43 [00:24<00:00,  1.77it/s]\n",
      "Generating embeddings: 100%|██████████| 34/34 [00:18<00:00,  1.86it/s]\n",
      "Generating embeddings: 100%|██████████| 20/20 [00:10<00:00,  1.86it/s]\n",
      "Parsing nodes: 100%|██████████| 20/20 [03:33<00:00, 10.68s/it]\n"
     ]
    }
   ],
   "source": [
    "embed_model = GeminiEmbedding(\n",
    "    model_name=\"models/embedding-001\", api_key=GOOGLE_API_KEY\n",
    ")\n",
    "splitter = SemanticSplitterNodeParser(\n",
    "    buffer_size=1, \n",
    "    breakpoint_percentile_threshold=95, \n",
    "    embed_model=embed_model\n",
    ")\n",
    "nodes = splitter.get_nodes_from_documents(documents, show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Groq(model=\"mixtral-8x7b-32768\", api_key=GROQ_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_25986/59880135.py:1: DeprecationWarning: Call to deprecated class method from_defaults. (ServiceContext is deprecated, please use `llama_index.settings.Settings` instead.) -- Deprecated since version 0.10.0.\n",
      "  service_context = ServiceContext.from_defaults(embed_model=embed_model, llm=llm)\n"
     ]
    }
   ],
   "source": [
    "service_context = ServiceContext.from_defaults(embed_model=embed_model, llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing nodes: 100%|██████████| 20/20 [00:00<00:00, 70.28it/s]\n",
      "Generating embeddings: 100%|██████████| 40/40 [00:21<00:00,  1.89it/s]\n"
     ]
    }
   ],
   "source": [
    "vector_index = VectorStoreIndex.from_documents(documents, show_progress=True, \n",
    "               service_context=service_context, node_parser=nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_index.storage_context.persist(persist_dir=\"./storage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_context = StorageContext.from_defaults(persist_dir=\"./storage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = load_index_from_storage(storage_context, service_context=service_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohere_rerank = CohereRerank(api_key=COHERE_API_KEY, top_n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine(service_context=service_context,\n",
    "                similarity_top_k=10,\n",
    "                node_postprocessors=[cohere_rerank],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Summarize all the documents\"\n",
    "resp = query_engine.query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The documents pertain to a publishing agreement and related information. The publishing agreement covers the distribution formats for the work, which include clothbound print book, paperback print book, ebook, and an open access online edition. The revenue sharing and royalties are outlined in Schedule E, and the work is subject to a Creative Commons License (CC BY-NC-ND 4.0), which is the most restrictive license allowing others to download and share the work, given that they credit the author, but cannot change or use it commercially.\\n\\nThe author is responsible for seeking permissions for non-original content, paying permission fees, and obtaining the right to include non-original content in the work. Metadata details for each non-original item include the title, digital file name, resource type, caption, copyright status, copyright holder, and license granted for use.\\n\\nThe publisher is responsible for providing a form for third parties to sign for non-original content. The author is committed to delivering the final, fully revised manuscript by 8/1/2019, and the publisher is responsible for editing, typesetting, designing, and publishing the work within 18 months of receiving a final, fully revised complete manuscript that has been approved by the Faculty Editorial Board and vetted and approved for production by the Publisher.\\n\\nThe total funding committed for the work is $6500, and the author's responsibility includes delivering the final, fully revised manuscript prepared for editing, design, and production by 8/1/2019. The publisher's responsibility includes editing, typesetting, designing, and publishing the work within 18 months of receiving a final, fully revised complete manuscript that has been approved by the Faculty Editorial Board and vetted and approved for production by the Publisher.\\n\\nThe author's responsibility includes delivering the final, fully revised manuscript prepared for editing, design, and production by 8/1/2019. The publisher's responsibility includes editing, typesetting, designing, and publishing the work within 18 months of receiving a final, fully revised complete manuscript that has been approved by the Faculty Editorial Board and vetted and approved for production by the Publisher.\\n\\nThe author is responsible for obtaining full written permission for the reproduction or quotation of all material beyond Fair Use and protected by existing copyright, bearing responsibility for all permission fees, and sending copies of the Work to all grantors of permission if requested.\\n\\nThe Press pledges to take all reasonable precautions with any manuscript, illustrations, or other material that you place in our hands. The author agrees to retain a duplicate copy of the manuscript. If there are any unique or especially valuable materials in the manuscript, the author must provide us with a detailed description, including value, along with written confirmation that such material is properly insured.\\n\\nThe Press has the authority to make the manuscript conform to the style that we believe most suitable for the Work. The author agrees to review the edited manuscript and return it to the Press by the date agreed upon and agrees to make no change of style or substance in the Work subsequent to this review. Should we find it necessary to retype, extensively edit, or redraw material in the manuscript, this work shall be performed by us and charged to the author.\\n\\nThe Press will send the author proofs of the Work, which the author agrees to read, correct, and return by the agreed-upon date. The author agrees to pay the cost of any alterations, except those owing to the editor's, compositor's, or printer's errors, in excess of one correction per five book pages.\\n\\nIf the Press considers an index necessary, the author agrees to prepare or have prepared at their expense an index to the Work in a form satisfactory to the Press and to return it by the date agreed upon.\\n\\nThe author agrees to correct or revise the first and subsequent editions of the Work at their own expense and to supply upon the Press's written request any material deemed necessary to keep the Work up to date.\\n\\nThe author agrees that while this Agreement remains in force, they will not without the Press's written permission publish any other book-length version of the Work or any book or media presentation of a similar character that will compete directly with the sale of this Work.\\n\\nThe agreement shall continue for the duration of the copyright on the original and all subsequent editions, subject to conditions agreed upon for earlier termination. The Press shall have the right to terminate this Agreement if the author has violated either of the conditions of the author's warranty.\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp.response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'AsyncOpenAI' from 'openai' (/home/kiwitech/Erloom-AI/lib/python3.10/site-packages/openai/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CallbackManager\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgemini\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GeminiEmbedding\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgroq\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Groq\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpostprocessor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcohere_rerank\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CohereRerank\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n",
      "File \u001b[0;32m~/Erloom-AI/lib/python3.10/site-packages/llama_index/llms/groq/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgroq\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Groq\n\u001b[1;32m      3\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGroq\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Erloom-AI/lib/python3.10/site-packages/llama_index/llms/groq/base.py:4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Any, Optional\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mopenai_like\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAILike\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mGroq\u001b[39;00m(OpenAILike):\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m      9\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     10\u001b[0m         model: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m     15\u001b[0m     ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Erloom-AI/lib/python3.10/site-packages/llama_index/llms/openai_like/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mopenai_like\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAILike\n\u001b[1;32m      3\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOpenAILike\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Erloom-AI/lib/python3.10/site-packages/llama_index/llms/openai_like/base.py:20\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstants\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DEFAULT_CONTEXT_WINDOW\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeneric_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     16\u001b[0m     async_stream_completion_response_to_chat_response,\n\u001b[1;32m     17\u001b[0m     completion_response_to_chat_response,\n\u001b[1;32m     18\u001b[0m     stream_completion_response_to_chat_response,\n\u001b[1;32m     19\u001b[0m )\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mopenai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAI, Tokenizer\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mOpenAILike\u001b[39;00m(OpenAI):\n",
      "File \u001b[0;32m~/Erloom-AI/lib/python3.10/site-packages/llama_index/llms/openai/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mopenai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AsyncOpenAI, OpenAI, SyncOpenAI, Tokenizer\n\u001b[1;32m      3\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOpenAI\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSyncOpenAI\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAsyncOpenAI\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Erloom-AI/lib/python3.10/site-packages/llama_index/llms/openai/base.py:60\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseOutputParser, PydanticProgramMode\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mopenai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     49\u001b[0m     create_retry_decorator,\n\u001b[1;32m     50\u001b[0m     from_openai_message,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     57\u001b[0m     to_openai_message_dicts,\n\u001b[1;32m     58\u001b[0m )\n\u001b[0;32m---> 60\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mopenai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AsyncOpenAI, AzureOpenAI\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mopenai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAI \u001b[38;5;28;01mas\u001b[39;00m SyncOpenAI\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mopenai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat_completion_chunk\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     63\u001b[0m     ChatCompletionChunk,\n\u001b[1;32m     64\u001b[0m     ChoiceDelta,\n\u001b[1;32m     65\u001b[0m     ChoiceDeltaToolCall,\n\u001b[1;32m     66\u001b[0m )\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'AsyncOpenAI' from 'openai' (/home/kiwitech/Erloom-AI/lib/python3.10/site-packages/openai/__init__.py)"
     ]
    }
   ],
   "source": [
    "from llama_index.core import StorageContext, ServiceContext, load_index_from_storage\n",
    "from llama_index.core.callbacks.base import CallbackManager\n",
    "from llama_index.embeddings.gemini import GeminiEmbedding\n",
    "from llama_index.llms.groq import Groq\n",
    "from llama_index.postprocessor.cohere_rerank import CohereRerank\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import gradio as gr\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "GOOGLE_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "COHERE_API_KEY = os.getenv(\"COHERE_API_KEY\")\n",
    "\n",
    "def query_function(query):\n",
    "    storage_context = StorageContext.from_defaults(persist_dir=\"./storage\")\n",
    "\n",
    "    embed_model = GeminiEmbedding(\n",
    "        model_name=\"models/embedding-001\", api_key=GOOGLE_API_KEY\n",
    "    ) \n",
    "\n",
    "    llm = Groq(model=\"mixtral-8x7b-32768\", api_key=GROQ_API_KEY)\n",
    "\n",
    "    service_context = ServiceContext.from_defaults(embed_model=embed_model, llm=llm,\n",
    "                        callback_manager=CallbackManager())\n",
    "    cohere_rerank = CohereRerank(api_key=COHERE_API_KEY, top_n=2)\n",
    "\n",
    "    index = load_index_from_storage(storage_context, service_context=service_context)\n",
    "\n",
    "    query_engine = index.as_query_engine(\n",
    "        service_context=service_context,\n",
    "        similarity_top_k=10,\n",
    "        node_postprocessors=[cohere_rerank],\n",
    "    )\n",
    "\n",
    "    response = query_engine.query(query)\n",
    "\n",
    "    return response.response_txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
